{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "import logging\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28.0\n"
     ]
    }
   ],
   "source": [
    "print(openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the clean data\n",
    "df = pd.read_csv('clean_data.csv')\n",
    "\n",
    "# Select 50% of the data\n",
    "half_data = df.sample(frac=0.5, random_state=1)\n",
    "\n",
    "# Drop the selected rows from the original DataFrame\n",
    "remaining_data = df.drop(half_data.index)\n",
    "\n",
    "# Save the half data to 'test_tweets.csv'\n",
    "half_data.to_csv('test_tweets.csv', index=False)\n",
    "\n",
    "# Save the remaining data back to 'clean_data.csv' or to a new file if preferred\n",
    "remaining_data.to_csv('clean_data_remaining.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"your key\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"API key not found. Please set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Define the new set of categories\n",
    "categories = [\n",
    "    \"Medical assistance\",\n",
    "    \"Shelter request\",\n",
    "    \"Supplies needed\",\n",
    "    \"Evacuation support\",\n",
    "    \"Rescue operations\",\n",
    "    \"Mental health support\",\n",
    "    \"Infrastructure repair\",\n",
    "    \"Animal rescue assistance\",\n",
    "    \"No assistance needed\",\n",
    "    \"Authority intervention (police, court, judges, ..)\"\n",
    "]\n",
    "\n",
    "# Function to classify a single tweet using OpenAI's ChatGPT\n",
    "def classify_tweet(content):\n",
    "    try:\n",
    "        prompt = (\n",
    "            \"You are a classifier for emergency-related tweets. \"\n",
    "            \"Please classify the following tweet into one of these categories only: \"\n",
    "            + \", \".join(categories) + \". \"\n",
    "            \"Respond with the category name only.\"\n",
    "        )\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": content}\n",
    "            ],\n",
    "            temperature=0  # Setting temperature to 0 for deterministic output\n",
    "        )\n",
    "        label = response.choices[0].message['content'].strip()\n",
    "        return label\n",
    "    except openai.error.RateLimitError as e:\n",
    "        if 'insufficient_quota' in str(e):\n",
    "            logging.error(\"Insufficient funds in OpenAI account. Please add more credits.\")\n",
    "            # Optionally wait and retry, or exit the script\n",
    "            time.sleep(60)  # Wait 1 minute and then retry (optional)\n",
    "            return classify_tweet(content)  # Retry classification\n",
    "        else:\n",
    "            logging.error(f\"Rate limit error: {e}\")\n",
    "            return \"Rate limit error\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error classifying tweet: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "# Function to classify tweets in a DataFrame\n",
    "def classify_tweets(df):\n",
    "    labels = []\n",
    "    for index, row in df.iterrows():\n",
    "        content = f\"{row['Title']} {row['Snippet']}\"\n",
    "        label = classify_tweet(content)\n",
    "        labels.append(label)\n",
    "        time.sleep(1)  # Adding a delay to avoid rate limiting\n",
    "    df[\"Label\"] = labels\n",
    "    return df\n",
    "\n",
    "def main(input_file, output_file):\n",
    "    # Read the CSV file\n",
    "    try:\n",
    "        df = pd.read_csv(input_file)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(\"Input CSV file not found.\")\n",
    "        return\n",
    "\n",
    "    # Classify tweets\n",
    "    logging.info(\"Classifying tweets...\")\n",
    "    df = classify_tweets(df)\n",
    "\n",
    "    # Save the classified tweets to a new CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    logging.info(f\"Classified tweets saved to {output_file}\")\n",
    "\n",
    "    # Print summary of classifications\n",
    "    summary = df[\"Label\"].value_counts()\n",
    "    print(\"Classification Summary:\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 14:39:57,836 - INFO - Classifying tweets...\n",
      "2024-11-06 17:14:29,774 - INFO - Classified tweets saved to classified_data_2.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Summary:\n",
      "Label\n",
      "No assistance needed                                   2234\n",
      "Authority intervention                                 1593\n",
      "Rescue operations                                       665\n",
      "Evacuation support                                      316\n",
      "Medical assistance                                      286\n",
      "Animal rescue assistance                                241\n",
      "Infrastructure repair                                   165\n",
      "Supplies needed                                         110\n",
      "Shelter request                                          53\n",
      "Mental health support                                    50\n",
      "Authority intervention (police, court, judges, ...)      46\n",
      "Authority intervention (police, court, judges)           33\n",
      "Authority intervention (police, court, judges, ..)        6\n",
      "Emergency assistance for Education in Lebanon             3\n",
      "Humanitarian aid                                          3\n",
      "Emergency assistance needed                               3\n",
      "Humanitarian assistance                                   3\n",
      "Humanitarian aid support                                  1\n",
      "Humanitarian assistance.                                  1\n",
      "Education assistance                                      1\n",
      "Financial advice                                          1\n",
      "Emergency appeal                                          1\n",
      "Humanitarian assistance for Gaza                          1\n",
      "Emergency relief efforts                                  1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace this section in Jupyter or interactive environments\n",
    "input_file = \"/home/moegho/Desktop/490_Project/clean_data_remaining.csv\"\n",
    "output_file = \"classified_data_2.csv\"\n",
    "main(input_file, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
